import streamlit as st
from transformers import GPT2LMHeadModel, GPT2Tokenizer
import torch

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
@st.cache_resource
def load_model():
    model_name = "sberbank-ai/rugpt3small_based_on_gpt2"
    tokenizer = GPT2Tokenizer.from_pretrained(model_name)
    model = GPT2LMHeadModel.from_pretrained(model_name)
    return model, tokenizer

model, tokenizer = load_model()

# –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å
st.title("üé§ –ë–∞—Ä–∞—à –ø–∏—à–µ—Ç —Å—Ç–∏—Ö–∏")
st.image("https://upload.wikimedia.org/wikipedia/ru/thumb/e/e4/Barash.png/220px-Barash.png ", width=150)
prompt = st.text_input("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–º—É —Å—Ç–∏—Ö–∞:", "–û—Å–µ–Ω–Ω–∏–π –ª–µ—Å")

if st.button("–ù–∞–ø–∏—Å–∞—Ç—å —Å—Ç–∏—Ö"):
    with st.spinner("–ë–∞—Ä–∞—à –¥—É–º–∞–µ—Ç..."):
        input_ids = tokenizer.encode(prompt, return_tensors="pt")
        output = model.generate(
            input_ids,
            max_length=150,
            num_beams=5,
            no_repeat_ngram_size=2,
            early_stopping=True,
            pad_token_id=tokenizer.eos_token_id
        )
        poem = tokenizer.decode(output[0], skip_special_tokens=True)
        st.markdown(f"### –í–æ—Ç —á—Ç–æ –Ω–∞–ø–∏—Å–∞–ª –ë–∞—Ä–∞—à:\n\n{poem}")
